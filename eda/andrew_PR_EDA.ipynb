{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some potential audiences are:\n",
    "\n",
    "1. Homeowners who want to increase the sale price of their homes through home improvement projects\n",
    "2. Advocacy groups who want to promote affordable housing\n",
    "3. Local elected officials who want to understand how their policy ideas (e.g. zoning changes, permitting) might impact home prices\n",
    "4. Real estate investors looking for potential \"fixer-uppers\" or \"tear-downs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three things to be sure you establish during this phase are:\n",
    "\n",
    "1. **Objectives:** what questions are you trying to answer, and for whom?\n",
    "2. **Project plan:** you may want to establish more formal project management practices, such as daily stand-ups or using a Trello board, to plan the time you have remaining. Regardless, you should determine the division of labor, communication expectations, and timeline.\n",
    "3. **Success criteria:** what does a successful project look like? How will you know when you have achieved it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ THIS: Import the following data files from https://info.kingcounty.gov/assessor/DataDownload/default.aspx\n",
    "## Download the files to local repo data directory\n",
    "> 1) Real Property Sales (.ZIP, csv) <BR>\n",
    "> 2) Parcel (.ZIP, csv) <BR>\n",
    "> 3) Residential Building (.ZIP, csv) <BR>\n",
    "> 4) Unit Breakdown (.ZIP)<BR>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.diagnostic import linear_rainbow, het_breuschpagan\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function named parse_2019(df) that takes a dataframe as the input.\n",
    "# It takes in a dataframe, looks for relevant columns, and then keeps the rows that\n",
    "# are in the year 2019.\n",
    "\n",
    "def parse_2019(df):\n",
    "    if 'DocumentDate' in df.columns:\n",
    "        df = df[pd.to_datetime(df['DocumentDate']).dt.year == 2019 ]\n",
    "    elif 'ChangeDate' in df.columns:\n",
    "        df = df[df['ChangeDate'].astype(str).str[:4] == '2019']\n",
    "    df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function get_data(create_csv)\n",
    "## If create_csv = True:\n",
    "##.   create a combined file rp_cons.csv from other csv files and return a dataframe rp_cons\n",
    "## If create_csv = False:\n",
    "##    return a data_frame with all columns from rp_cons.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_data (create_csv):\n",
    "\n",
    "    if create_csv == False:    \n",
    "        rp_cons = pd.read_csv(\"data/rp_cons.csv\")   \n",
    "    return rp_cons\n",
    "    \n",
    "    df_rp_sales = get_sale()\n",
    "    df_parcel = get_parcel()\n",
    "    df_res_bldg = get_resBldg()\n",
    "    df_unit_breakdown = get_unit_breakdown()\n",
    "    \n",
    "    \n",
    "    return df_rpsales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read EXTR_RPSale.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data File: EXTR_RPSale.csv -------------------------------------------------------------\n",
    "#Table: EXTR_RPSale \n",
    "#Keys: Major, Minor\n",
    "#Fields: SalePrice, PropertyType, PrincipalUse\n",
    "def get_sale():\n",
    "    df_rp_sales = pd.read_csv('data/EXTR_RPSale.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "    print(\"Before Filer EXTR_RPSale.csv: \", df_rp_sales.shape)\n",
    "\n",
    "    # Filter the following columns from EXTR_RPsale table\n",
    "    # Primary key: 'Major', 'Minor' \n",
    "    # Select Fields: 'DocumentDate', 'SalePrice', 'PropertyType', 'PrincipalUse', 'PropertyClass\n",
    "    cols = list(df_rp_sales.columns)\n",
    "    df_rp_sales = df_rp_sales[cols[1:5] + cols[14:16] + cols[22:23]]\n",
    "    df_rp_sales = parse_2019(df_rp_sales)\n",
    "    print(\"After Filer EXTR_RPSale.csv: \", df_rp_sales.shape)  \n",
    "    return df_rp_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read EXTR_Parcel.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data File: EXTR_Parcel.csv\n",
    "#Table: EXTR_Parcel\n",
    "#Keys: Major, Minor\n",
    "#Fields: PropType, Area, SubArea,DistrictName, SqFtLot, WaterSystem, SewerSystem, Access, WaterProblems, AirportNoise, TrafficNoise,PowerLines,  LandSlideHazard, SeismicHazard\n",
    "\n",
    "def get_parcel():\n",
    "    df_parcel = pd.read_csv('data/EXTR_Parcel.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "    print(\"Before EXTR_Parcel.csv: \", df_parcel.shape)\n",
    "    df_parcel.columns\n",
    "    \n",
    "    # Filter the following columns from EXTR_Parcel table\n",
    "    # Primary key: 'Major', 'Minor' \n",
    "    # Select Fields: PropType, Area, SubArea, DistrictName, SqFtLot, WaterSystem, SewerSystem, Access, WaterProblems, AirportNoise, TrafficNoise,PowerLines,  LandSlideHazard, SeismicHazard\n",
    "    cols = list(df_parcel.columns)\n",
    "    df_parcel = df_parcel[cols[:2] + cols[10:11] + cols[15:16]]  ######## Change this\n",
    "    df_parcel = parse_2019(df_parcel)\n",
    "    print(\"After Filer EXTR_Parcel.csv: \", df_par.shape)\n",
    "    return df_parcel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Read EXTR_ResBldg.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data File: EXTR_ResBldg.csv\n",
    "#Table: EXTR_ResBldg\n",
    "#Keys: Major, Minor\n",
    "#Fields: BldgNbr, NbrLivingUnits, Address, BuildingNumber, Stories, BldgGrade, SqFt1stFloor, SqFtHalfFloor, SqFt2ndFloor, SqFtUpperFloor, SqFtTotLiving, SqFtTotBasement, SqFtFinBasement, SqFtOpenPorch, SqFtEnclosedPorch, SqFtDeck, HeatSystem, HeatSource, Bedrooms, BathHafCouunt, Bath3qtrCount, BathFullCount, FpSingleStory, FpMultiStory, YrBuilt, YrRenovated \n",
    "def get_resBldg():\n",
    "    df_res_bldg = pd.read_csv('data/EXTR_ResBldg.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "    print(\"Before EXTR_ResBldg.csv: \", df_res_bldg.shape)\n",
    "\n",
    "    # Filter the following columns from EXTR_Parcel table\n",
    "    # Primary key: 'Major', 'Minor' \n",
    "    # Select Fields: PropType, Area, SubArea, DistrictName, SqFtLot, WaterSystem, SewerSystem, Access, WaterProblems, AirportNoise, TrafficNoise,PowerLines,  LandSlideHazard, SeismicHazard\n",
    "    cols = list(df_parcel.columns)\n",
    "    df_res_bldg = df_res_bldg[cols[:2] + cols[10:11] + cols[15:16]]  ######## Change this    \n",
    "    df_res_bldg = parse_2018(df_res_bldg)\n",
    "    print(\"After Filer EXTR_Parcel.csv: \", df_res_bldg.shape)\n",
    "    return df_res_bldg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Read EXTR_UnitBreakdown.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data File: EXTR_UnitBreakdown.csv\n",
    "#Table: EXTR_UnitBreakdown\n",
    "#Keys: Major, Minor\n",
    "#Fields:  'UnitTypeItemId', 'NbrThisType', 'SqFt','NbrBedrooms', 'NbrBaths'\n",
    "def get_unitbreakdown():\n",
    "    df_unit_breakdown = pd.read_csv('data/EXTR_UnitBreakdown.csv', encoding = \"ISO-8859-1\", low_memory=False)\n",
    "    print(\"EXTR_UnitBreakdown: \", df_unit_breakdown.shape)\n",
    "    ###todo extract column\n",
    "    return df_unit_breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andrew's scratchwork below:\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Major', 'Minor', 'DocumentDate', 'SalePrice', 'PropertyType',\n",
       "       'PrincipalUse', 'PropertyClass'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rp_sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Major', 'Minor', 'PropType', 'DistrictName'], dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_par.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Major', 'Minor', 'BldgNbr', 'NbrLivingUnits', 'Address',\n",
       "       'BuildingNumber', 'Fraction', 'DirectionPrefix', 'StreetName',\n",
       "       'StreetType', 'DirectionSuffix', 'ZipCode', 'Stories', 'BldgGrade',\n",
       "       'BldgGradeVar', 'SqFt1stFloor', 'SqFtHalfFloor', 'SqFt2ndFloor',\n",
       "       'SqFtUpperFloor', 'SqFtUnfinFull', 'SqFtUnfinHalf', 'SqFtTotLiving',\n",
       "       'SqFtTotBasement', 'SqFtFinBasement', 'FinBasementGrade',\n",
       "       'SqFtGarageBasement', 'SqFtGarageAttached', 'DaylightBasement',\n",
       "       'SqFtOpenPorch', 'SqFtEnclosedPorch', 'SqFtDeck', 'HeatSystem',\n",
       "       'HeatSource', 'BrickStone', 'ViewUtilization', 'Bedrooms',\n",
       "       'BathHalfCount', 'Bath3qtrCount', 'BathFullCount', 'FpSingleStory',\n",
       "       'FpMultiStory', 'FpFreestanding', 'FpAdditional', 'YrBuilt',\n",
       "       'YrRenovated', 'PcntComplete', 'Obsolescence', 'PcntNetCondition',\n",
       "       'Condition', 'AddnlCost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_bldg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Major', 'Minor', 'TaxYr', 'OmitYr', 'ApprLandVal', 'ApprImpsVal',\n",
       "       'ApprImpIncr', 'LandVal', 'ImpsVal', 'TaxValReason', 'TaxStatus',\n",
       "       'LevyCode', 'ChangeDate', 'ChangeDocId', 'Reason', 'SplitCode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value_history.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Major', 'Minor', 'UnitTypeItemId', 'NbrThisType', 'SqFt',\n",
       "       'NbrBedrooms', 'NbrBaths'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unit_breakdown.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rp_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Y:\\Users\\awyeh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['DocumentDate'] = pd.to_datetime(df['DocumentDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Major</th>\n",
       "      <th>Minor</th>\n",
       "      <th>DocumentDate</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>PrincipalUse</th>\n",
       "      <th>PropertyClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213043</td>\n",
       "      <td>0120</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>560000</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Major Minor DocumentDate  SalePrice  PropertyType  PrincipalUse  \\\n",
       "4  213043  0120   2019-12-20     560000             3             6   \n",
       "\n",
       "   PropertyClass  \n",
       "4              8  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['DocumentDate'].dt.year == 2019 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Y:\\Users\\awyeh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Major</th>\n",
       "      <th>Minor</th>\n",
       "      <th>DocumentDate</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>PrincipalUse</th>\n",
       "      <th>PropertyClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>213043</td>\n",
       "      <td>0120</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>560000</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Major Minor DocumentDate  SalePrice  PropertyType  PrincipalUse  \\\n",
       "4  213043  0120   2019-12-20     560000             3             6   \n",
       "\n",
       "   PropertyClass  \n",
       "4              8  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DocumentDate'] = pd.to_datetime(df['DocumentDate'])\n",
    "df[df['DocumentDate'].dt.year == 2019 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1994'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value_history['ChangeDate'][0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_history = df_value_history[df_value_history['ChangeDate'].astype(str).str[:4] == '2019']\n",
    "df_value_history.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (linreg_env)",
   "language": "python",
   "name": "linreg-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
